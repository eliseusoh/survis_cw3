const generatedBibEntries = {
    "Fryer2017": {
        "abstract": "Novel technology can be a powerful tool for enhancing students' interest in many learning domains. However, the sustainability and overall impact of such interest is unclear. This study tests the longer-term effects of technology on students' task and course interest. The experimental study was conducted with students in foreign language classes (n\u00a0",
        "author": "Luke K. Fryer, Mary Ainley, Andrew Thompson, Aaron Gibson, Zelinda Sherlock",
        "doi": "https://doi.org/10.1016/j.chb.2017.05.045",
        "issn": "0747-5632",
        "journal": "Computers in Human Behavior",
        "keywords": "type:experimental, CMC, Interest, Novelty-effect, Education and technology, Language learning, Chatbot",
        "number": "2017",
        "pages": "461-468",
        "series": "Computers in Human Behavior",
        "title": "Stimulating and sustaining interest in a language course: An experimental comparison of Chatbot and Human task partners",
        "type": "article",
        "url": "https://www.sciencedirect.com/science/article/pii/S0747563217303667",
        "volume": "75",
        "year": "2017"
    },
    "Hill2015": {
        "abstract": "This study analyzed how communication changes when people communicate with an intelligent agent as opposed to with another human. We compared 100 instant messaging conversations to 100 exchanges with the popular chatbot Cleverbot along seven dimensions: words per message, words per conversation, messages per conversation, word uniqueness, and use of profanity, shorthand, and emoticons. A MANOVA indicated that people communicated with the chatbot for longer durations (but with shorter messages) than they did with another human. Additionally, human\u2013chatbot communication lacked much of the richness of vocabulary found in conversations among people, and exhibited greater profanity. These results suggest that while human language skills transfer easily to human\u2013chatbot communication, there are notable differences in the content and quality of such conversations.",
        "author": "Jennifer Hill, Randolph Ford, Ingrid Farreras",
        "doi": "https://doi.org/10.1016/j.chb.2015.02.026",
        "issn": "0747-5632",
        "journal": "Computers in Human Behavior",
        "keywords": "type:comparative, CMC, Instant messaging, IM, Chatbot, Cleverbot",
        "number": "2015",
        "pages": "245-250",
        "series": "Computers in Human Behavior",
        "title": "Real conversations with artificial intelligence: A comparison between human\u2013human online conversations and human\u2013chatbot conversations",
        "type": "article",
        "url": "https://www.sciencedirect.com/science/article/pii/S0747563215001247",
        "volume": "49",
        "year": "2015"
    },
    "Lei2021": {
        "abstract": "Purpose \u2013 Chatbot users\u2019 communication experience with disembodied conversational agents was compared with instant messaging (IM) users\u2019 communication experience with human conversational agents. The purpose of this paper is to identify what affects users\u2019 intention to reuse and whether they perceive any difference between the two. Design/methodology/approach \u2013 A conceptual model was developed based on computer-mediated communication (CMC) and interpersonal communication theories. Data were collected online from four different continents (North America, Europe, Asia and Australia). Partial least squares structural equation modeling was applied to examine the research model. Findings \u2013 The findings mainly reveal that media richness and social presence positively influence trust and reuse intention through task attraction and social attraction; IM users reported significantly higher scores in terms of communication experience, perceived attractiveness of the conversational agent, and trust than chatbot users; users\u2019 trust in the conversational agents is mainly determined by perceived task attraction. Research limitations/implications \u2013 Customers\u2019 evaluation of the communication environment is positively related to their perceived competence of the conversational agent which ultimately affect their intention to reuse chatbot/IM. The findings reveal determinants of chatbot/IM adoption which have rarely been mentioned by previous work. Practical implications \u2013 Practitioners should note that consumers in general still prefer to interact with human conversational agents. Practitioners should contemplate how to combine chatbot and human resources effectively to deliver the best customer service. Originality/value \u2013 This study goes beyond the Computer as Social Actor paradigm and Technology Acceptance Model to understand chatbot and IM adoption. It is among one of the first studies that compare chatbot and IM use experience in the tourism and hospitality literature",
        "author": "Lei, Soey Sut Ieng and Shen, Haili and Ye, Shun",
        "doi": "10.1108/IJCHM-12-2020-1399",
        "journal": "International Journal of Contemporary Hospitality Management",
        "keywords": "type:comparative, Artificial intelligence, Chatbot, Computer-mediated communication, Instant messaging, Interpersonal attraction, Reuse intention",
        "month": "08",
        "number": "11",
        "pages": "3977- 3995",
        "series": "International Journal of Contemporary Hospitality Management",
        "title": "A comparison between chatbot and human service: customer perception and reuse intention",
        "type": "article",
        "url": "https://www.emerald.com/insight/content/doi/10.1108/IJCHM-12-2020-1399/full/pdf?title",
        "volume": "33",
        "year": "2021"
    },
    "Li2023": {
        "abstract": "With the application of artificial intelligence (AI) technology in organizational frontlines, customers' service experiences have begun to shift from interactions with service personnel to those with technology. However, only a few studies have explored customers' behavioral switch from human-mediated services to technology-mediated ones with regard to the application of AI in frontline services. Based on the push\u2013pull mooring framework, this study explored the determinants that affect consumers\u2019 behavioral switch from using human agents to using AI-based conversational agents. Data collected from 441 users of banking services were analyzed using structural equation modeling. The findings reveal that both push effects\u2014namely, low empathy and low adaptability\u2014and pull effects, including anytime/anywhere connectivity, association, visibility, and personalization, have positive influences on switching behavior. Finally, in addition to having a direct influence on switching behavior, frequency of service use positively moderated the relationship between pull effects and switching behavior.",
        "author": "Chia-Ying Li, Jin-Ting Zhang",
        "doi": "https://doi.org/10.1016/j.jretconser.2023.103264",
        "issn": "0969-6989",
        "journal": "Journal of Retailing and Consumer Services",
        "keywords": "type:comparative, Push\u2013pull mooring framework, Conversational agents, Anytime/anywhere connectivity, Association, and visibility",
        "number": "2023",
        "pages": "103264",
        "series": "Journal of Retailing and Consumer Services",
        "title": "Chatbots or me? Consumers\u2019 switching between human agents and conversational agents",
        "type": "article",
        "url": "https://www.sciencedirect.com/science/article/pii/S0969698923000115",
        "volume": "72",
        "year": "2023"
    },
    "Lou2022": {
        "abstract": " AbstractArtificial intelligence (AI) is rapidly reconstructing consumer experiences with brands in recent years. However, there have been the unsettled debates on whether humans react to robots (e.g., chatbots) in the same way as they do to other humans, and how the intrinsic strength of AI (i.e., autonomous processing and synthetization of information) and humans (i.e., emotional intelligence) factor in the human-AI interactions in brand communication settings. Hence, this study investigates the conditions under which a service entity of a brand can optimize their potential. To this end, the current study conceptualizes and operationalizes two dimensions that define chatbots\u2019 capabilities \u2013 message contingency (i.e., contingency-based interactivity) and emotional intelligence (i.e., sympathy). Based on two experiments, we found that, regarding the same online customer service of an apparel brand, participants rated the human employee to be more competent and warmer than a chatbot. When a human employee who expresses sympathy to the afflicted customer during the conversation, participants considered the employee to be more competent when he/she also exhibits contingency (vs. no contingency) during the conversation, which in turn, elicited higher patronage intentions among participants.",
        "author": "Chen Lou, Hyunjin Kang, Caleb H. Tse",
        "doi": "10.1080/02650487.2021.1951510",
        "eprint": "https://doi.org/10.1080/02650487.2021.1951510",
        "journal": "International Journal of Advertising",
        "keywords": "type:experimental, Brand  communication,  schema  congruity,  interactivity,  sympathy,  competence,  AI",
        "number": "4",
        "pages": "655-684",
        "publisher": "Routledge",
        "series": "International Journal of Advertising",
        "title": "Bots vs. humans: how schema congruity, contingency-based interactivity, and sympathy influence consumer perceptions and patronage intentions",
        "type": "article",
        "url": "https://doi.org/10.1080/02650487.2021.1951510",
        "volume": "41",
        "year": "2022"
    },
    "Luo2019": {
        "abstract": "Empowered by artificial intelligence (AI), chatbots are surging as new technologies with both business potential and customer pushback. This study exploits field experiment data on more than 6,200 customers who are randomized to receive highly structured outbound sales calls from chatbots or human workers. Results suggest that undisclosed chatbots are as effective as proficient workers and four times more effective than inexperienced workers in engendering customer purchases. However, a disclosure of chatbot identity before the machine\u2013customer conversation reduces purchase rates by more than 79.7%. Additional analyses find that these results are robust to nonresponse bias and hang-ups, and the chatbot disclosure substantially decreases call length. Exploration of the mechanisms reveals that when customers know the conversational partner is not a human, they are curt and purchase less because they perceive the disclosed bot as less knowledgeable and less empathetic. The negative disclosure effect seems to be driven by a subjective human perception against machines, despite the objective competence of AI chatbots. Fortunately, such negative impact can be mitigated by a late disclosure timing strategy and customer prior AI experience. These findings offer useful implications for chatbot applications, customer targeting, and advertising in conversational commerce.",
        "author": "Luo, Xueming and Tong, Siliang and Fang, Zheng and Qu, Zhe",
        "doi": "10.1287/mksc.2019.1192",
        "journal": "Marketing Science",
        "keywords": "type:experimental, artificial intelligence, chatbot, conversational commerce, new technology, disclosure",
        "month": "09",
        "number": "6",
        "pages": "937-947",
        "series": "Marketing Science",
        "title": "Frontiers: Machines vs. Humans: The Impact of Artificial Intelligence Chatbot Disclosure on Customer Purchases",
        "type": "article",
        "url": "https://www.researchgate.net/publication/335959930_Frontiers_Machines_vs_Humans_The_Impact_of_Artificial_Intelligence_Chatbot_Disclosure_on_Customer_Purchases ",
        "volume": "38",
        "year": "2019"
    },
    "Mittal2016": {
        "abstract": "A chatbot is a software that interacts with humans using natural language processing and pattern matching techniques to understand questions and give relevant answers. In this paper, we evaluate the performance of chatbots ALICE, Jabberwacky and Rose on various criteria. We compare their performance with that of humans. Our general conclusion is that chatbots perform equally well as humans but they cannot replace humans completely.",
        "author": "Mittal, Amit and Agrawal, Ayushi and Chouksey, Ayushi and Shriwas, Rachna and Agrawal, Saloni",
        "doi": "10.17148/IJARCCE.2016.53253",
        "journal": "IJARCCE ",
        "keywords": "type:experimental, Chatbot, natural language processing, human computer interaction, pattern matching",
        "month": "03",
        "number": "3",
        "pages": "1055-1057",
        "series": "IJARCCE ",
        "title": "A Comparative Study of Chatbots and Humans",
        "type": "article",
        "url": "https://www.researchgate.net/profile/Amit-Mittal-14/publication/338335856_IJARCCE_A_Comparative_Study_of_Chatbots_and_Humans/links/5e0d912a4585159aa4ab6dcb/IJARCCE-A-Comparative-Study-of-Chatbots-and-Humans.pdf ",
        "volume": "5",
        "year": "2016"
    },
    "Mou2017": {
        "abstract": "As human-machine communication has yet to become prevalent, the rules of interactions between human and intelligent machines need to be explored. This study aims to investigate a specific question: During human users' initial interactions with artificial intelligence, would they reveal their personality traits and communicative attributes differently from human-human interactions? A sample of 245 participants was recruited to view six targets' twelve conversation transcripts on a social media platform: Half with a chatbot Microsoft's Little Ice, and half with human friends. The findings suggested that when the targets interacted with Little Ice, they demonstrated different personality traits and communication attributes from interacting with humans. Specifically, users tended to be more open, more agreeable, more extroverted, more conscientious and self-disclosing when interacting with humans than with AI. The findings not only echo Mischel's cognitive-affective processing system model but also complement the Computers Are Social Actors Paradigm. Theoretical implications were discussed.",
        "author": "Yi Mou, Kun Xu",
        "doi": "https://doi.org/10.1016/j.chb.2017.02.067",
        "issn": "0747-5632",
        "journal": "Computers in Human Behavior",
        "keywords": "type:exploratory, Human-machine communication, The Computers Are Social Actors Paradigm, The cognitive-affective processing system, Artificial intelligence, Chatbot, Social interaction",
        "number": "2017",
        "pages": "432-440",
        "series": "Computers in Human Behavior",
        "title": "The media inequality: Comparing the initial human-human and human-ai social interactions",
        "type": "article",
        "url": "https://www.sciencedirect.com/science/article/pii/S0747563217301486",
        "volume": "72",
        "year": "2017"
    },
    "Tsai2021": {
        "abstract": "Based on the theoretical framework of agency effect, this study examined the role of affect in influencing the effects of chatbot versus human brand representatives in the context of health marketing communication about HPV vaccines. We conducted a 2 (perceived agency: chatbot vs. human) \u00d7 3 (affect elicitation: embarrassment, anger, neutral) between-subject lab experiment with 142 participants, who were randomly assigned to interact with either a perceived chatbot or a human representative. Key findings from self-reported and behavioral data highlight the complexity of consumer\u2013chatbot communication. Specifically, participants reported lower interaction satisfaction with the chatbot than with the human representative when anger was evoked. However, participants were more likely to disclose concerns of HPV risks and provide more elaborate answers to the perceived human representative when embarrassment was elicited. Overall, the chatbot performed comparably to the human representative in terms of perceived usefulness and influence over participants' compliance intention in all emotional contexts. The findings complement the Computers as Social Actors paradigm and offer strategic guidelines to capitalize on the relative advantages of chatbot versus human representatives.",
        "author": "Tsai, Wanhsiu and Lun, Di and Carcioppolo, Nicholas and Chuan, Ching Hua",
        "doi": "10.1002/mar.21556",
        "journal": "Psychology & Marketing",
        "keywords": "type:experimental, affect, anger, chatbot, embarrassment, health communication, health marketing,human\u2010machine interaction, perceived agency, vaccine",
        "month": "12",
        "number": "12",
        "pages": "2377-2392",
        "series": "Psychology & Marketing",
        "title": "Human versus chatbot: Understanding the role of emotion in health marketing communication for vaccines",
        "type": "article",
        "url": "https://www.researchgate.net/publication/353497769_Human_versus_chatbot_Understanding_the_role_of_emotion_in_health_marketing_communication_for_vaccines",
        "volume": "38",
        "year": "2021"
    },
    "Zhou2023": {
        "abstract": "Chatbots have been applied to computer-mediated communication to replace human agents due to their high efficiency and cost-effectiveness. However, their outcomes are not always desirable, and limited guidance exists on how chatbots impact users' perceptions of the communication process. Drawing on cue-filtered-out theories and multiple resource theory, this study investigated the impacts of the communicating agent (chatbot vs. human agent) on anticipated communication quality and the underlying mechanism. Two experimental studies revealed that users' anticipated communication quality was lower with chatbots than with human agents due to the serial mediating role of self-focused attention and user empathy. Moreover, moderation analyses found that a multiple-choice communication strategy for chatbots can enhance users' anticipated communication quality by impacting self-focused attention compared to an open-ended strategy. The findings contribute to the knowledge of the processes driving users\u2019 anticipated communication quality toward chatbot applications and offer managerial implications for chatbots and communication strategies.",
        "author": "Qi Zhou, Bin Li, Lei Han, Min Jou",
        "doi": "https://doi.org/10.1016/j.chb.2023.107674",
        "issn": "0747-5632",
        "journal": "Computers in Human Behavior",
        "keywords": "type:experimental, Chatbot, Human agent, Communication quality, Self-focused attention, Empathy, Communication strategy",
        "number": "2023",
        "pages": "107674",
        "series": "Computers in Human Behavior",
        "title": "Talking to a bot or a wall? How chatbots vs. human agents affect anticipated communication quality",
        "type": "article",
        "url": "https://www.sciencedirect.com/science/article/pii/S0747563223000250",
        "volume": "143",
        "year": "2023"
    }
};