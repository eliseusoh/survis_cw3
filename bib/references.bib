@article{Hill201,
title = {Real conversations with artificial intelligence: A comparison between human–human online conversations and human–chatbot conversations},
journal = {Computers in Human Behavior},
volume = {49},
pages = {245-250},
series = {Computers in Human Behavior},
year = {2015},
number = {2015},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2015.02.026},
url = {https://www.sciencedirect.com/science/article/pii/S0747563215001247},
author = {Jennifer Hill, Randolph Ford, Ingrid Farreras},
keywords = {type:comparative, CMC, Instant messaging, IM, Chatbot, Cleverbot},
abstract = {This study analyzed how communication changes when people communicate with an intelligent agent as opposed to with another human. We compared 100 instant messaging conversations to 100 exchanges with the popular chatbot Cleverbot along seven dimensions: words per message, words per conversation, messages per conversation, word uniqueness, and use of profanity, shorthand, and emoticons. A MANOVA indicated that people communicated with the chatbot for longer durations (but with shorter messages) than they did with another human. Additionally, human–chatbot communication lacked much of the richness of vocabulary found in conversations among people, and exhibited greater profanity. These results suggest that while human language skills transfer easily to human–chatbot communication, there are notable differences in the content and quality of such conversations.}
} 

@article{Li2023,
title = {Chatbots or me? Consumers’ switching between human agents and conversational agents},
journal = {Journal of Retailing and Consumer Services},
volume = {72},
series = {Journal of Retailing and Consumer Services}, 
pages = {103264},
year = {2023},
number = {2023},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2023.103264},
url = {https://www.sciencedirect.com/science/article/pii/S0969698923000115},
author = {Chia-Ying Li, Jin-Ting Zhang},
keywords = {type:comparative, Push–pull mooring framework, Conversational agents, Anytime/anywhere connectivity, Association, and visibility},
abstract = {With the application of artificial intelligence (AI) technology in organizational frontlines, customers' service experiences have begun to shift from interactions with service personnel to those with technology. However, only a few studies have explored customers' behavioral switch from human-mediated services to technology-mediated ones with regard to the application of AI in frontline services. Based on the push–pull mooring framework, this study explored the determinants that affect consumers’ behavioral switch from using human agents to using AI-based conversational agents. Data collected from 441 users of banking services were analyzed using structural equation modeling. The findings reveal that both push effects—namely, low empathy and low adaptability—and pull effects, including anytime/anywhere connectivity, association, visibility, and personalization, have positive influences on switching behavior. Finally, in addition to having a direct influence on switching behavior, frequency of service use positively moderated the relationship between pull effects and switching behavior.}
} 

@article{Zhou2023,
title = {Talking to a bot or a wall? How chatbots vs. human agents affect anticipated communication quality},
journal = {Computers in Human Behavior},
volume = {143},
series = {Computers in Human Behavior}, 
pages = {107674},
year = {2023},
number = {2023},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2023.107674},
url = {https://www.sciencedirect.com/science/article/pii/S0747563223000250},
author = {Qi Zhou, Bin Li, Lei Han, Min Jou},
keywords = {type:experimental, Chatbot, Human agent, Communication quality, Self-focused attention, Empathy, Communication strategy},
abstract = {Chatbots have been applied to computer-mediated communication to replace human agents due to their high efficiency and cost-effectiveness. However, their outcomes are not always desirable, and limited guidance exists on how chatbots impact users' perceptions of the communication process. Drawing on cue-filtered-out theories and multiple resource theory, this study investigated the impacts of the communicating agent (chatbot vs. human agent) on anticipated communication quality and the underlying mechanism. Two experimental studies revealed that users' anticipated communication quality was lower with chatbots than with human agents due to the serial mediating role of self-focused attention and user empathy. Moreover, moderation analyses found that a multiple-choice communication strategy for chatbots can enhance users' anticipated communication quality by impacting self-focused attention compared to an open-ended strategy. The findings contribute to the knowledge of the processes driving users’ anticipated communication quality toward chatbot applications and offer managerial implications for chatbots and communication strategies.}
} 

@article{Mou2017,
title = {The media inequality: Comparing the initial human-human and human-ai social interactions},
journal = {Computers in Human Behavior},
volume = {72},
number = {2017},
series = {Computers in Human Behavior},
pages = {432-440},
year = {2017},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2017.02.067},
url = {https://www.sciencedirect.com/science/article/pii/S0747563217301486},
author = {Yi Mou, Kun Xu},
keywords = {type:exploratory, Human-machine communication, The Computers Are Social Actors Paradigm, The cognitive-affective processing system, Artificial intelligence, Chatbot, Social interaction},
abstract = {As human-machine communication has yet to become prevalent, the rules of interactions between human and intelligent machines need to be explored. This study aims to investigate a specific question: During human users' initial interactions with artificial intelligence, would they reveal their personality traits and communicative attributes differently from human-human interactions? A sample of 245 participants was recruited to view six targets' twelve conversation transcripts on a social media platform: Half with a chatbot Microsoft's Little Ice, and half with human friends. The findings suggested that when the targets interacted with Little Ice, they demonstrated different personality traits and communication attributes from interacting with humans. Specifically, users tended to be more open, more agreeable, more extroverted, more conscientious and self-disclosing when interacting with humans than with AI. The findings not only echo Mischel's cognitive-affective processing system model but also complement the Computers Are Social Actors Paradigm. Theoretical implications were discussed.}
} 

@article{Fryer2017,
title = {Stimulating and sustaining interest in a language course: An experimental comparison of Chatbot and Human task partners},
journal = {Computers in Human Behavior},
volume = {75},
pages = {461-468},
series = {Computers in Human Behavior},
year = {2017},
number = {2017},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2017.05.045},
url = {https://www.sciencedirect.com/science/article/pii/S0747563217303667},
author = {Luke K. Fryer, Mary Ainley, Andrew Thompson, Aaron Gibson, Zelinda Sherlock},
keywords = {type:experimental, CMC, Interest, Novelty-effect, Education and technology, Language learning, Chatbot},
abstract = {Novel technology can be a powerful tool for enhancing students' interest in many learning domains. However, the sustainability and overall impact of such interest is unclear. This study tests the longer-term effects of technology on students' task and course interest. The experimental study was conducted with students in foreign language classes (n = 122): a 12-week experimental trial that included pre- and post-course interest, and a sequence of task interest measures. Employing a counterbalanced design, at three week intervals students engaged in separate speaking tasks with each of a Human and “Chatbot” partner. Students' interest in successive tasks and in the course (pre-post), were used to assess differential partner effects and course interest development trajectories. Comparisons of task interest under different partner conditions over time indicated a significant drop in students' task interest with the Chatbot but not Human partner. After accounting for initial course interest, Structural Equation Modelling indicated that only task interest with the Human partner contributed to developing course interest. While Human partner task interest predicted future course interest, task interest under Chatbot partner conditions did not. Under Chatbot partner conditions there was a drop in task interest after the first task: a novelty effect. Implications for theory and practice are discussed.}
} 

@article{Luo2019,
author = {Luo, Xueming and Tong, Siliang and Fang, Zheng and Qu, Zhe},
year = {2019},
month = {09},
number = {6},
volume = {38},
series = {Marketing Science},
pages = {937-947},
title = {Frontiers: Machines vs. Humans: The Impact of Artificial Intelligence Chatbot Disclosure on Customer Purchases},
journal = {Marketing Science},
keywords = {type:experimental, artificial intelligence, chatbot, conversational commerce, new technology, disclosure},
doi = {10.1287/mksc.2019.1192},
url = {https://www.researchgate.net/publication/335959930_Frontiers_Machines_vs_Humans_The_Impact_of_Artificial_Intelligence_Chatbot_Disclosure_on_Customer_Purchases },
abstract = {Empowered by artificial intelligence (AI), chatbots are surging as new technologies with both business potential and customer pushback. This study exploits field experiment data on more than 6,200 customers who are randomized to receive highly structured outbound sales calls from chatbots or human workers. Results suggest that undisclosed chatbots are as effective as proficient workers and four times more effective than inexperienced workers in engendering customer purchases. However, a disclosure of chatbot identity before the machine–customer conversation reduces purchase rates by more than 79.7%. Additional analyses find that these results are robust to nonresponse bias and hang-ups, and the chatbot disclosure substantially decreases call length. Exploration of the mechanisms reveals that when customers know the conversational partner is not a human, they are curt and purchase less because they perceive the disclosed bot as less knowledgeable and less empathetic. The negative disclosure effect seems to be driven by a subjective human perception against machines, despite the objective competence of AI chatbots. Fortunately, such negative impact can be mitigated by a late disclosure timing strategy and customer prior AI experience. These findings offer useful implications for chatbot applications, customer targeting, and advertising in conversational commerce.}
} 

@article{Lou2022,
author = {Chen Lou, Hyunjin Kang, Caleb H. Tse},
title = {Bots vs. humans: how schema congruity, contingency-based interactivity, and sympathy influence consumer perceptions and patronage intentions},
journal = {International Journal of Advertising},
volume = {41},
series = {International Journal of Advertising},
number = {4},
pages = {655-684},
year  = {2022},
publisher = {Routledge},
keywords = {type:experimental, Brand  communication,  schema  congruity,  interactivity,  sympathy,  competence,  AI}, 
doi = {10.1080/02650487.2021.1951510},
URL = {https://doi.org/10.1080/02650487.2021.1951510},
eprint = {https://doi.org/10.1080/02650487.2021.1951510},
abstract = { AbstractArtificial intelligence (AI) is rapidly reconstructing consumer experiences with brands in recent years. However, there have been the unsettled debates on whether humans react to robots (e.g., chatbots) in the same way as they do to other humans, and how the intrinsic strength of AI (i.e., autonomous processing and synthetization of information) and humans (i.e., emotional intelligence) factor in the human-AI interactions in brand communication settings. Hence, this study investigates the conditions under which a service entity of a brand can optimize their potential. To this end, the current study conceptualizes and operationalizes two dimensions that define chatbots’ capabilities – message contingency (i.e., contingency-based interactivity) and emotional intelligence (i.e., sympathy). Based on two experiments, we found that, regarding the same online customer service of an apparel brand, participants rated the human employee to be more competent and warmer than a chatbot. When a human employee who expresses sympathy to the afflicted customer during the conversation, participants considered the employee to be more competent when he/she also exhibits contingency (vs. no contingency) during the conversation, which in turn, elicited higher patronage intentions among participants. }
} 

@article{Mittal2016,
author = {Mittal, Amit and Agrawal, Ayushi and Chouksey, Ayushi and Shriwas, Rachna and Agrawal, Saloni},
year = {2016},
month = {03},
series = {IJARCCE }, 
journal = {IJARCCE },
volume = {5},
number = {3},
pages = {1055-1057},
title = {A Comparative Study of Chatbots and Humans},
keywords = {type:experimental, Chatbot, natural language processing, human computer interaction, pattern matching},
doi = {10.17148/IJARCCE.2016.53253},
url = {https://www.researchgate.net/profile/Amit-Mittal-14/publication/338335856_IJARCCE_A_Comparative_Study_of_Chatbots_and_Humans/links/5e0d912a4585159aa4ab6dcb/IJARCCE-A-Comparative-Study-of-Chatbots-and-Humans.pdf },
abstract = {A chatbot is a software that interacts with humans using natural language processing and pattern matching
techniques to understand questions and give relevant answers. In this paper, we evaluate the performance of chatbots
ALICE, Jabberwacky and Rose on various criteria. We compare their performance with that of humans. Our general
conclusion is that chatbots perform equally well as humans but they cannot replace humans completely.}
}

@article{Lei2021,
author = {Lei, Soey Sut Ieng and Shen, Haili and Ye, Shun},
year = {2021},
number = {11},
month = {08},
volume = {33}, 
series = {International Journal of Contemporary Hospitality Management}, 
pages = {3977- 3995},
title = {A comparison between chatbot and human service: customer perception and reuse intention},
journal = {International Journal of Contemporary Hospitality Management},
doi = {10.1108/IJCHM-12-2020-1399},
url = {https://www.emerald.com/insight/content/doi/10.1108/IJCHM-12-2020-1399/full/pdf?title=a-comparison-between-chatbot-and-human-service-customer-perception-and-reuse-intention },
abstract = {Purpose – Chatbot users’ communication experience with disembodied conversational agents was
compared with instant messaging (IM) users’ communication experience with human conversational agents.
The purpose of this paper is to identify what affects users’ intention to reuse and whether they perceive any
difference between the two.
Design/methodology/approach – A conceptual model was developed based on computer-mediated
communication (CMC) and interpersonal communication theories. Data were collected online from four
different continents (North America, Europe, Asia and Australia). Partial least squares structural equation
modeling was applied to examine the research model.
Findings – The findings mainly reveal that media richness and social presence positively influence trust
and reuse intention through task attraction and social attraction; IM users reported significantly higher scores
in terms of communication experience, perceived attractiveness of the conversational agent, and trust than
chatbot users; users’ trust in the conversational agents is mainly determined by perceived task attraction.
Research limitations/implications – Customers’ evaluation of the communication environment is
positively related to their perceived competence of the conversational agent which ultimately affect their
intention to reuse chatbot/IM. The findings reveal determinants of chatbot/IM adoption which have rarely
been mentioned by previous work.
Practical implications – Practitioners should note that consumers in general still prefer to interact with
human conversational agents. Practitioners should contemplate how to combine chatbot and human
resources effectively to deliver the best customer service.
Originality/value – This study goes beyond the Computer as Social Actor paradigm and Technology
Acceptance Model to understand chatbot and IM adoption. It is among one of the first studies that compare
chatbot and IM use experience in the tourism and hospitality literature},
keywords = {type:comparative, Artificial intelligence, Chatbot, Computer-mediated communication, Instant messaging,
Interpersonal attraction, Reuse intention}
}

@article{Tsai2021,
author = {Tsai, Wanhsiu and Lun, Di and Carcioppolo, Nicholas and Chuan, Ching Hua},
year = {2021},
number = {12},
month = {12},
pages = {2377-2392},
abstract = {Based on the theoretical framework of agency effect, this study examined the role of affect in influencing the effects of chatbot versus human brand representatives in the context of health marketing communication about HPV vaccines. We conducted a 2 (perceived agency: chatbot vs. human) × 3 (affect elicitation: embarrassment, anger, neutral) between-subject lab experiment with 142 participants, who were randomly assigned to interact with either a perceived chatbot or a human representative. Key findings from self-reported and behavioral data highlight the complexity of consumer–chatbot communication. Specifically, participants reported lower interaction satisfaction with the chatbot than with the human representative when anger was evoked. However, participants were more likely to disclose concerns of HPV risks and provide more elaborate answers to the perceived human representative when embarrassment was elicited. Overall, the chatbot performed comparably to the human representative in terms of perceived usefulness and influence over participants' compliance intention in all emotional contexts. The findings complement the Computers as Social Actors paradigm and offer strategic guidelines to capitalize on the relative advantages of chatbot versus human representatives.},
title = {Human versus chatbot: Understanding the role of emotion in health marketing communication for vaccines},
volume = {38},
series = {Psychology & Marketing}, 
keywords = {type:experimental, affect, anger, chatbot, embarrassment, health communication, health marketing,human‐machine interaction, perceived agency, vaccine},
journal = {Psychology & Marketing},
doi = {10.1002/mar.21556},
url = {https://www.researchgate.net/publication/353497769_Human_versus_chatbot_Understanding_the_role_of_emotion_in_health_marketing_communication_for_vaccines }
}

